\chapter{Security Considerations on Bare Metal}

This section will discuss the configuration settings to consider when setting up a server on bare metal, including
the common attacks vectors. There are many reasons that one would use a OS image off-the-shelf, and even a secured
image can't protect the user from their own misconfiguration. We must have some mechanism of finding issues and
fixing them to ensure that there are no holes.

\begin{center}
    \begin{tabular}{||p{0.3\textwidth} p{0.3\textwidth} p{0.3\textwidth}||}
        \hline
        Issue & Attack Type & Affected Components \\ [0.5ex]
        \hline\hline
        Outdated Software & Arbitrary Code Execution & OS Processes \\
        \hline
        Unencrypted communications & InfoLeak, Man-In-The-Middle Attack & Network, Authentication \\
        \hline
        Permissive Firewalls or iptables & InfoLeak, RCE & Network \\
        \hline
        Privileged users & RCE & Access Control \\ [0.5ex]
        \hline
    \end{tabular}
\end{center}

\section{Software Updates and Versioning}

\subsection{Reasoning for Keeping Software Up-to-Date}

One of the most important steps to take when maintaining a server is to keep the software up to date. Thankfully, this
is simple to achieve with most software today. Native package managers can make upgrading a package or software program
a one-line command. Additionally, many programs today will have self-update mechanisms which will migrate data
automatically, without input from the user.

We must be sure to apply these updates as soon as they become available. All large software projects likely contains
bugs or exploits which could be used by an attacker with knowledge of their existence. A study by the RAND corporation
examined over 200 historical zero-day vulnerabilities in commonly-used software and determined that zero-day vulnerabilities
have an average life expectancy of 6.9 years~\cite{cdi_proquest_reports_1875964326}. Once an exploit is found and reported
to the project's maintainers, there is generally a period between when the vulerability is fixed in a software update and
the exploit is announced to the public. In order to gain protection from these exploits as soon as possible, it is
critical to update software as soon as updated are available.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=1\textwidth]{./fig/Updating software.drawio.png}
    \end{center}
    \caption{Out of date software can lead to a number of different attacks. Once an attacker has determined that a system is using an exploitable version of software, they can craft a payload with input that will trigger the exploit and execute arbitrary code that will damage the system or leak information.}
    \label{fig2}
\end{figure}

\subsection{Scanning for Available Updates}

Scanning a system for software which should be updated is as simple as checking the version of installed software and
packages against the newest version in major trusted repositories. Upgrading most software and packages will be simple,
but there is always the possibility of incompatible versions of packages or software which would require code changes
and will take longer to complete. This may be the most common reason for not upgrading packages once available but leaves
a system vulnerable to attacks.

If the system is Debian-based, one can run:

\begin{lstlisting}[style=AMMA, language=bash]
apt update
apt list --upgradable
\end{lstlisting}

To update repository lists and determine which packages have updates available. Then, running

\begin{lstlisting}[style=AMMA, language=bash]
apt upgrade -y
\end{lstlisting}

Will automatically upgrade all available packages. Of course, this should be done with care because there is no gurarantee
that the new packages will not contain breaking changes.

\section{Remote control}

\subsection{User Access}

Assuming that the user is not accessing the machine from a physical terminal, there must be some kind of remote
connection to the machine. This connection should be encrypted and secured by cryptographic keys to prevent attacks.
A basic SSH connection will satisfy these requirements, so alternatives must be avoided even if the communication is
over a private network. We can check whether the current user has logged in via ssh by using 'who am i'. Additionally,
we will want to check the configuration file to ensure that SSH is set up to disallow passwords.

We can check if the current user is logged in via ssh by using:

\begin{lstlisting}[style=AMMA, language=bash]
ps aux | grep "sshd: $(whoami)@$(who am i | awk '{print $2}')" | wc -l
\end{lstlisting}

Which will print a '1' if the current session is using ssh. We can then check whether the ssh configuration is secure
by using

\begin{lstlisting}[style=AMMA, language=bash]
cat /etc/ssh/sshd_config | grep "^PasswordAuthentication"
cat /etc/ssh/sshd_config | grep "^PermitRootLogin"
\end{lstlisting}

We for both, we should either have no result or the setting is set to 'no', such as 'PasswordAuthentication no".

\subsection{Encrypted Communications}

Any unencrypted communication is vulnerable to a man-in-the middle attack, as explained by John Richter~\cite{monkey_in_the_middle}.
This can lead to information leak and possibly unauthorized access should any passwords be transferred. We can classify
this as a vulnerability in the network or firewall of the system. All remote control of the machine should be done over
encrypted channels, and if not then anyone who is able to intercept the packets could determine exactly what was being
sent to the system, including plaintext passwords.

If the user is not currently logged in via SSH, the solution would be to disable whatever method was used to access the
machine and use SSH instead. Today, the main way to access a remote machine is via SSH, so we can assume that any
machine should have the ability to host an SSH server daemon. However, it may be necessary for the host to use some
remote GUI system, in which case we should ensure that the communications are over a secure channel such as HTTPS and the
authentication meets a standard set by the organization.

Checking whether communications are done over HTTPS should be done at the application-level instead of at the OS level.
However, if we wish to do so, it is possible to set up firewalls using iptables to block all outbound traffic that is
not HTTPS or SSH. If we wish to do so, we can set this with

\begin{lstlisting}[style=AMMA, langugage=bash]
iptables -P INPUT DROP
iptables -P OUTPUT DROP
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A OUTPUT -t filter -p tcp --dport https -j ACCEPT
iptables -A OUTPUT -t filter -p udp --dport https -j ACCEPT
\end{lstlisting}

However this will certainly break many applications using the network, which is why it is best to ensure secure communication
at the application level.

\subsection{Remediation}
To ensure that ssh is enabled and enforced on a system, the following steps should be taken:

\begin{enumerate}
    \item Install sshd. sshd should be pre-installed on most operating systems, but can be downloaded from a trusted package repository or be built from source
    \item Start sshd on system boot. If systemctl is used, we can do this by running 'systemctl enable sshd'
    \item Generate keys for all users. Ensure all users have generated private keys and transferred them to the server
    \item Disable password authentication. Passwords should never be used for authentication of a user over ssh. This can be disabled by editing the /etc/ssh/sshd\_config file. Additional measures can be taken when editing this file, such as preventing port forwarding or root logins.
\end{enumerate}

\section{Network Security and Firewall Configuration}

\subsection{Importance of Firewalls}

Networks should be configured using principles of least permissions, with only the necessary ports and addresses open for
connection. If the machine is hosting virtual machines, we can use it as a firewall for the guests by setting rules using
iptables. In a public cloud environment, it may be necessary to allow incoming connections to the guests. If this is the
case then we should make sure that the iptables configuration can be changed programmatically, or another solution must
be used.

\subsection{Necessary Configuration and Remediation}

We can check the iptables configuration programmatically but the needs of each organization will be dramatically different.
Therefore, it is not feasible to determine programmatically whether the configuration is an issue without knowledge of
the system requirements. However, we can still check whether firewall rules are set in place and give the user a warning
if nothing is configured.

\section{Reduce User Privileges to a Minimum}

\subsection{Principle of Least-Privilege}

It is essential that the host machine has been set up using principles of least permissions. We hope that a malicious
guest VM or compromised container cannot escape from its process, but the host should still anticipate this possibility
and limit the attack surface on the native operating system. A sysadmin should take care to ensure that the system is
up-to-date and the programs running have been secured,but this can be time-consuming and error-prone to do by hand.
By using a tool such as Canary, we can quickly evaluate a system and fix trivial errors.

\subsection{Leaky Files}

One way that systems become compromised or secrets are leaked are from seemingly innocuous files which contain
secrets or system information. Log files can contain information such as password in plain text or keys which could
be used to gain access to other systems. These files can be put into a list and checked by Canary by checking
whether the user running the process can read or write to the files. This can eliminate the vast majority of trivial
security issues, and prevent any damage from occurring if a process is compromised or an unauthorized user gains access.

\subsection{Phishing}

We should also consider that a user's passwords or private keys could fall into the hands of an attacker through a
simple phish attempt. Phishing attempts are extremely common and an alarming number of people will fall victim to them,
as shown by a study by Software World Intelligence~\cite{cdi_gale_infotrac_627280924}. Administrators should assume that
users will at some point give up their passwords or keys, and that account could be used to find sensitive information.
Although Canary can't detect whether a user or group should have access to a specific file, it can easily determine
whether that file is readable and report it to the end-user.

\subsection{Malicious Actors and Code Vulnerabilities}

Consider a system which has an unknown zero-day vulnerability which can be exploited. For example, consider the recent
linux kernel vulnerability CVE-2022-0185, which enables container breakout~\cite{CVE-2022-0185}. The attacker may use
this to gain access to the system and execute arbitrary code. However, if we make sure to reduce the permissions for
users down to the bare minimum, we may be able to save any sensitive data from leaking and prevent the actor from
gaining control of the system. An attack of this manner can be considered privilege escalation since the user which was
intended to only do one thing, such as run a file server, would now be able to execute programs which it was never
intended to.

Preventing an attacker from gaining sudo privilege is of upmost importance, so a user with sudo access should never be
used to run long-running programs on the host system unless necessary. Canary can check whether the current user has
sudo access or whether any processes in a list of PID's are running with sudo privilege.  Of course, this can't be
easily fixed with another script so the system administrator must address the issue. Many processes must run with sudo
permissions to work correctly, but in most cases we can simply create a new user with only the permissions necessary for
the program to work.

AppArmor or similar software should be also be utilized to minimize the damage that a malicious process can cause on a
system. These profiles can be used in conjunction with a user with minimal permissions to ensure that intruders are
prevented from accessing sensitive data.
