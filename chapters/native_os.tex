
\chapter{Security Considerations on Bare Metal}

This section will discuss the configuration settings to consider when setting up a server on bare metal, including
the common attacks vectors. There are many reasons that one would use an off-the-shelf OS image, and even a secured
image can't protect the user from their own misconfiguration. We must have some mechanism for finding issues and
fixing them to ensure that there are no holes.

\begin{table}
    \caption{Scanning and remediation for native OS issues}
    \begin{center}
        \begin{tabular}{||p{0.3\textwidth} p{0.3\textwidth} p{0.3\textwidth}||}
            \hline
            Issue                            & Scanning Type             & Remediation Type \\ [0.5ex]
            \hline\hline
            Outdated Software                & CLI Action                & CLI Action                          \\
            \hline
            Unencrypted communications       & Configuration File Search & Configuration File Find and Replace \\
            \hline
            Permissive Firewalls or iptables & DSL Configuration Search  & Manual                              \\
            \hline
            User Readable Files              & CLI Action                & CLI Action                          \\
            \hline
            Privileged users                 & CLI Action                & CLI Action \\ [0.5ex]
            \hline
        \end{tabular}
    \end{center}
\end{table}


\section{Software Updates and Versioning}

\subsection{Reasoning for Keeping Software Up-to-Date}

One of the most important steps to take when maintaining a server is to keep the software up to date. Thankfully, this
is simple to achieve with most software today. Native package managers can make upgrading a package or software program
a one-line command. Additionally, many programs today will have self-update mechanisms which will migrate data
automatically, without input from the user.

We must be sure to apply these updates as soon as they become available. All large software projects likely contains
bugs or exploits which could be used by an attacker with knowledge of their existence. A study by the RAND corporation
examined over 200 historical zero-day vulnerabilities in commonly-used software and determined that zero-day vulnerabilities
have an average life expectancy of 6.9 years~\cite{cdi_proquest_reports_1875964326}. Once an exploit is found and reported
to the project's maintainers, there is generally a period between when the vulnerability is fixed in a software update and
the exploit is announced to the public. To gain protection from these exploits as soon as possible, it is
critical to update software as soon as updates are available.

\begin{figure}[h]
    \label{fig2}
    \caption{Out of date software can lead to a number of different attacks. Once an attacker has determined that a system is using an exploitable version of software, they can craft a payload with input that will trigger the exploit and execute arbitrary code that will damage the system or leak information.}
    \begin{center}
        \includegraphics[width=1\textwidth]{./fig/Updating software.drawio.png}
    \end{center}
\end{figure}

\subsection{Scanning for Available Updates}

Scanning a system for software that should be updated is as simple as checking the version of installed software and
packages against the newest version in major trusted repositories. Upgrading most software and packages will be simple,
but there is always the possibility of incompatible versions of packages or software which would require code changes
and will take longer to complete. This may be the most common reason for not upgrading packages once available but leaves
a system vulnerable to attacks.

If the system is Debian-based, one can run:

\begin{lstlisting}[style=AMMA, language=BASH]
apt update
apt list --upgradable
\end{lstlisting}

To update repository lists and determine which packages have updates available. Then, running

\begin{lstlisting}[style=AMMA, language=BASH]
apt upgrade -y
\end{lstlisting}

Will automatically upgrade all available packages. Of course, this should be done with care because there is no guarantee
that the new packages will not contain breaking changes.


\section{Remote control}

\subsection{User Access}

Assuming that the user is not accessing the machine from a physical terminal, there must be some kind of remote
connection to the machine. This connection should be encrypted and secured by cryptographic keys to prevent attacks.
A basic SSH connection will satisfy these requirements, so alternatives must be avoided even if the communication is
over a private network. We can check whether the current user has logged in via ssh by using 'who am i'. Additionally,
we will want to check the configuration file to ensure that SSH is set up to disallow passwords.

We can check if the current user is logged in via ssh by using:

\begin{lstlisting}[style=AMMA, language=BASH]
ps aux | grep "sshd: $(whoami)@$(who am i | awk '{print $2}')" | wc -l
\end{lstlisting}

Which will print a '1' if the current session is using ssh. We can then check whether the ssh configuration is secure
by using:

\begin{lstlisting}[style=AMMA, language=BASH]
cat /etc/ssh/sshd_config | grep "^PasswordAuthentication"
cat /etc/ssh/sshd_config | grep "^PermitRootLogin"
\end{lstlisting}

We should either have no result or the setting is set to 'no', such as 'PasswordAuthentication no". We can
then fix these issues with a simple sed command, such as:

\begin{lstlisting}[style=AMMA, language=BASH]
sed -i 's/PasswordAuthentication yes/PasswordAuthentication no/g' /etc/ssh/sshd_config
\end{lstlisting}

\subsection{Encrypted Communications}

Any unencrypted communication is vulnerable to a man-in-the-middle attack, as explained by John Richter~\cite{monkey_in_the_middle}.
This can lead to information leaks and possibly unauthorized access should any passwords be transferred. We can classify
this as a vulnerability in the network or firewall of the system. All remote control of the machine should be done over
encrypted channels, and if not then anyone who can intercept the packets could determine exactly what was being
sent to the system, including plaintext passwords.

If the user is not currently logged in via SSH, the solution would be to disable whatever method was used to access the
machine and use SSH instead. Today, the main way to access a remote machine is via SSH, so we can assume that any
machine should have the ability to host an SSH server daemon. However, it may be necessary for the host to use some
remote GUI system, in which case we should ensure that the communications are over a secure channel such as HTTPS and the
authentication meets a standard set by the organization.

Checking whether communications are done over HTTPS should be done at the application level instead of at the OS level.
However, if we wish to do so, it is possible to set up firewalls using iptables to block all outbound traffic that is
not HTTPS or SSH. If we wish to do so, we can set this with

\begin{lstlisting}[style=AMMA, language=BASH]
iptables -P INPUT DROP
iptables -P OUTPUT DROP
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
iptables -A OUTPUT -t filter -p tcp --dport https -j ACCEPT
iptables -A OUTPUT -t filter -p udp --dport https -j ACCEPT
\end{lstlisting}

However, this will certainly break many applications using the network, which is why it is best to ensure secure communication
at the application level.

\subsection{Remediation}
To ensure that ssh is enabled and enforced on a system, the following steps should be taken:

\begin{enumerate}
    \item Install sshd. Sshd should be pre-installed on most operating systems but can be downloaded from a trusted package repository or be built from source.
    \item Start sshd on system boot. If systemctl is used, we can do this by running 'systemctl enable sshd'.
    \item Generate keys for all users. Ensure all users have generated private keys and transferred them to the server.
    \item Disable password authentication. Passwords should never be used for authentication of a user over ssh. This can be disabled by editing the /etc/ssh/sshd\_config file. Additional measures can be taken when editing this file, such as preventing port forwarding or root logins.
\end{enumerate}


\section{Network Security and Firewall Configuration}

\subsection{Importance of Firewalls}

Networks should be configured using principles of least permissions, with only the necessary ports and addresses open for
connection. If the machine is hosting virtual machines, we can use it as a firewall for the guests by setting rules using
iptables. In a public cloud environment, it may be necessary to allow incoming connections to the guests. If this is the
case then we should make sure that the iptables configuration can be changed programmatically, or another solution must
be used.

\subsection{Necessary Configuration and Remediation}

We can check the iptables configuration programmatically but the needs of each organization will be dramatically different.
Therefore, it is not feasible to determine programmatically whether the configuration is an issue without knowledge of
the system requirements. However, we can still check whether firewall rules are set in place and give the user a warning
if nothing is configured.


\section{Reduce User Privileges to a Minimum}

\subsection{Principle of Least-Privilege}

The host machine must be set up using principles of least permissions. We hope that a malicious
guest VM or compromised container cannot escape from its process, but the host should still anticipate this possibility
and limit the attack surface on the native operating system. A sysadmin should take care to ensure that the system is
up-to-date and the programs running have been secured but this can be time-consuming and error-prone to do by hand.
By using a tool such as Canary, we can quickly evaluate a system and fix trivial errors.

For example, we can check that

\subsection{Leaky Files}

One way that systems become compromised or secrets are leaked is from seemingly innocuous files which contain
secrets or system information. Log files can contain information such as passwords in plain text or keys which could
be used to gain access to other systems. These files can be put into a list and checked by Canary by checking
whether the user running the process can read or write to the files. This can eliminate the vast majority of trivial
security issues, and prevent any damage from occurring if a process is compromised or an unauthorized user gains access.

As an exmpale, if a system is using Nginx for a reverse proxy we can check the permissions on the log files with

\begin{lstlisting}[style=AMMA, language=BASH]
test -r /var/log/nginx/access.log && echo 'readable'
\end{lstlisting}

Which will print 'readable' if the file is readable. Any user can do this against a list of filenames. If the user
finds an interesting log file, it would be simple to send the file contents back to the terminal or download it to
analyze later. This issue could be resolved by reducing the permissions on the file or by removing the user's membership
from a certain group. If the user was in a group called logreader for example, we could remove this access by running

\begin{lstlisting}[style=AMMA, language=BASH]
gpasswd -d [username] logreader
\end{lstlisting}

Or if we wish to reduce the file to only be readable for the file's owners:

\begin{lstlisting}[style=AMMA, language=BASH]
chmod 600 /var/log/nginx/access.log
\end{lstlisting}

It is good practice to refrain from passing sensitive data into log files whenever possible, but even without
sensitive data a log file could be used to infer information about a system which could give an attacker clues as to
weak points in the system's security.

\subsection{Phishing}

We should also consider that a user's passwords or private keys could fall into the hands of an attacker through a
simple phish attempt. Phishing attempts are extremely common and an alarming number of people will fall victim to them,
as shown by a study by Software World Intelligence~\cite{cdi_gale_infotrac_627280924}. Administrators should assume that
users will at some point give up their passwords or keys and that accounts could be used to find sensitive information.
Although Canary can't detect whether a user or group should have access to a specific file, it can easily determine
whether that file is readable and report it to the end-user.

\subsection{Malicious Actors and Code Vulnerabilities}

Consider a system that has an unknown zero-day vulnerability that can be exploited. For example, consider the recent
Linux kernel vulnerability CVE-2022-0185, which enables container breakout~\cite{CVE-2022-0185}. The attacker may use
this to gain access to the system and execute arbitrary code. However, if we make sure to reduce the permissions for
users down to the bare minimum, we may be able to save any sensitive data from leaking and prevent the actor from
gaining control of the system. An attack of this manner can be considered privilege escalation since the user who was
intended to only do one thing, such as run a file server, would now be able to execute programs they were never
intended to execute.

Preventing an attacker from gaining sudo privilege is of utmost importance, so a user with sudo access should never be
used to run long-running programs on the host system unless necessary. Canary can check whether the current user has
sudo access or whether any processes in a list of PIDs are running with sudo privilege. Of course, this can't be
easily fixed with another script so the system administrator must address the issue. Many processes must run with sudo
permissions to work correctly, but in most cases, we can simply create a new user with only the permissions necessary for
the program to work.

AppArmor or similar software should be utilized to minimize the damage that a malicious process can cause to a
system. These profiles can be used in conjunction with a user with minimal permissions to ensure that intruders are
prevented from accessing sensitive data.
